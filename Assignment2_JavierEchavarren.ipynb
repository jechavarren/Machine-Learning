{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z7_hx8SJJR4-"},"source":["# Assignment 2 - Logistic Regression & Naive Bayes\n","\n","Due by 11:59pm, Feb 24, 2023"]},{"cell_type":"markdown","metadata":{"id":"pyGrk2X_J_1h"},"source":["## Theory Questions (Full points: 40, each question 4 points)"]},{"cell_type":"markdown","metadata":{"id":"b8OnMEI0JXxA"},"source":["1. Explain the importance of setting up learning rate in the gradient descent based methods. "]},{"cell_type":"markdown","metadata":{"id":"uv3iz5dBJX7Z"},"source":["**Answer:** The learning rate is a parameter used in gradient descent methods that controls how much the weights of the model  change for each iteration. If the learning rate is too low, the model will learn slower and spend too much time to converge, however, if the learning rate is too high , the model will change too much after each iteration and may not converge easily, overshooting the global minimum. Therefore, it is important to find the optimal learning rate that converges the model to its best performance in the shortest amount of time."]},{"cell_type":"markdown","metadata":{"id":"wO8kErgCJX-P"},"source":["2. What is the stochastic gradient descent? Why do we need stochastic gradient descent?"]},{"cell_type":"markdown","metadata":{"id":"nEviYAL2JeWs"},"source":["**Answer:** Stochastic gradient descent is an optimization technique used in Machine Learning to update model parameters. It is an iterative algorithm that takes random samples of data, trains the model on these samples, and then train the updated model with new samples of data. We need Stochastic Gradient Descent because it is more computationally efficient than batch gradient descent, as it only uses a subset of the training data to train the model in each iteration. "]},{"cell_type":"markdown","metadata":{"id":"9vQD3sgwJYBS"},"source":["3. Explain the reasons to perform feature scaling."]},{"cell_type":"markdown","metadata":{"id":"t-e37RdDJfmd"},"source":["**Answer:** Feature scaling is a method used to normalize the range of independent variables or features in data. It is important for the following reasons:\n","\n","1. It levels out the importance between different features when calculating distance between points.\n","\n","2. Gradient descent converges much faster with feature scaling than without it.\n","\n","3. It levels the influence of different weights in the loss function when using regularization as part of the loss function."]},{"cell_type":"markdown","metadata":{"id":"dOqhvEpuJYEX"},"source":["4. What is the probabilistic generative model?"]},{"cell_type":"markdown","metadata":{"id":"rf5JjDFDJe6G"},"source":["**Answer:** In statistical classification, a probabilistic generative model is a type of generative model that uses probability distributions to generate data samples. These models are used in machine learning to model the distribution of data, generate new data samples that are similar to the original data or make predictions about future data samples by using the probability distributions of data."]},{"cell_type":"markdown","metadata":{"id":"W8V802XDJjxe"},"source":["5. Explain how we perform maximum likelihood."]},{"cell_type":"markdown","metadata":{"id":"S3PrgB7kJl99"},"source":["**Answer:** We perform maximum likelihood by calculating the probability of ocurrence for each data point for our model given our current parameters and changing these parameters so that we maximize the probability of occurrence of our dataset."]},{"cell_type":"markdown","metadata":{"id":"3kUcM98LJj9N"},"source":["6. Explain the reasons about using cross entropy loss in logistic regression."]},{"cell_type":"markdown","metadata":{"id":"xuECRF2PJk81"},"source":["**Answer:** Cross entropy loss is often used as the cost function in logistic regression. It measures the difference between predicted and actual probabilities, and is used to optimize the model's parameters. Cross entropy loss is useful as it is closely related to the concept of information theory, and can be used to measure the uncertainty of a model's predictions. Additionally, cross entropy loss is more robust to outliers than other cost functions, and can handle cases where the probabilities of the predicted and actual classes are very different."]},{"cell_type":"markdown","metadata":{"id":"q8bCRVRaJkBP"},"source":["7. Explain the differences between discriminative and generative model.\n"]},{"cell_type":"markdown","source":["**Answer:**\n","\n","Discriminative models are used to predict labels or classes given input data and are used in classification tasks. These models learn the conditional probability of a given label y given the data x. Examples of these models are logistic regression and support vector machines.\n","\n","Generative models are models used to model the joint probability of a given data point x and its label y. We can use this information to generate new data points with its associated labels or predict the probability of each occurrence. Examples of generative models are Hidden Markov Models and Naive Bayes."],"metadata":{"id":"YEdAdRiu1ksO"}},{"cell_type":"markdown","source":["8. What is N-folds? Explain the reasons why we need N-folds. "],"metadata":{"id":"dcZpkIc01Rwe"}},{"cell_type":"markdown","metadata":{"id":"R2KIVplzJlYt"},"source":["**Answer:** N-folds is a cross-validation technique used to evaluate machine learning models. The technique divides the dataset into N equal-size subsamples and use iteratively each subsample for testing and the remaining for training. This process is repeated N times, so that each subsample is used for testing once. Finally, we average the results to obtain the final model performance.\n","\n","We need N-folds because it allows us to use all the data for testing and training, but at the same time reducing overfitting, which helps us make better use of the available data."]},{"cell_type":"markdown","metadata":{"id":"RCL0MZN6JkET"},"source":["9. Bishop's Book \"Pattern Recognition and Machine learning\" - Exercise 4.12"]},{"cell_type":"markdown","metadata":{"id":"M-h519EbJmbz"},"source":["**Answer:**\n","$ σ(a)= \\frac{1}{1+e^{-a}} \\\\\n","σ\\prime(a)= \\frac{e^{-a}}{(1+e^{-a})^2} = \\frac{1}{1+e^{-a}} \\cdot \\frac{e^{-a}}{1+e^{-a}} = σ(a) ⋅ (1+\\frac{e^{-a}}{1+e^{-a}}-1)= σ(a) ⋅ (1+\\frac{-1}{1+e^{-a}}) = \\sigma(a) \\cdot (1-\\sigma(a))\n","$"]},{"cell_type":"markdown","source":["10. Bishop's Book \"Pattern Recognition and Machine learning\" - Exercise 4.13"],"metadata":{"id":"4_JyVbXB0LSH"}},{"cell_type":"markdown","source":["**Answer:**\n","$ E(w)=-\\sum_{n=1}^{N} {t_n ln(y_n)+(1-t_n)ln(1-y_n)} \\\\\n","\\frac{\\partial E}{\\partial y_n} =  -\\frac{t_n}{y_n} + \\frac{1-t_n}{1-y_n} = \\frac{y_n(1-t_n)-t_n(1-y_n)}{y_n(1-y_n)} = \\frac{y_n-t_n}{y_n(1-y_n)} $\n","\n","we know that \n","\n","$ \\frac{\\partial y_n}{\\partial a_n}=\\sigma(a_n) \\cdot (1-\\sigma(a_n))=y_n(1-y_n)\n","$\n","\n","and \n","\n","$ \\nabla a_n= \\phi_n \\\\\n","$\n","\n","so, finally\n","\n","$\n","\\nabla E= \\sum_{n=1}^{N} \\frac{\\partial E}{\\partial y_n} \\frac{\\partial y_n}{\\partial a_n} \\nabla a_n =  \\sum_{n=1}^{N}(y_n-t_n)\\phi_n\n","$"],"metadata":{"id":"8JYA083y0Z7Q"}},{"cell_type":"markdown","metadata":{"id":"8AiWTVDf7cZ2"},"source":["## Programming Questions (Full points: 60, each question 30 points)"]},{"cell_type":"code","metadata":{"id":"hUXdV3L376cA","executionInfo":{"status":"ok","timestamp":1677381801406,"user_tz":360,"elapsed":1677,"user":{"displayName":"Javier Echavarren Suárez","userId":"10032767525210246133"}}},"source":["# Do not edit the codes in this cell\n","# load required library\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.datasets import load_wine\n","# load dataset\n","x, y = load_wine(return_X_y=True)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8iwaee_T-Urj"},"source":["### - Logistic Regression"]},{"cell_type":"markdown","source":["0. train_test_split (Done in the below cell)\n","\n","We **randomly** split data into train and test set. The number of training data and testing data is 100 and 30, respectively. Do not modify the split data. You need to use training data to train your model and obtain an optimal solution. Finally, using your model with the optimal solution to predict the testing data. "],"metadata":{"id":"zyrt2Ka7VFYK"}},{"cell_type":"code","metadata":{"id":"9M1DAu9XPY8E","executionInfo":{"status":"ok","timestamp":1677381804417,"user_tz":360,"elapsed":156,"user":{"displayName":"Javier Echavarren Suárez","userId":"10032767525210246133"}}},"source":["# Do not edit the codes in this cell\n","# We split train and test data for logistic regression function\n","\n","test_lists = [0, 4, 5, 7, 13, 15, 19, 27, 28, 30, 31, 34, 39, 47, 63, 74, 78, 83, 90, 92, 95, 97, 103, 113, 119, 122, 123, 125, 126, 127]\n","\n","x = x[:130, :]\n","y = y[:130]\n","\n","# training data: you can use it to training your model.\n","train_x = np.array([sub_x for index, sub_x in enumerate(x) if index not in test_lists])\n","train_y = np.array([sub_y for index, sub_y in enumerate(y) if index not in test_lists])\n","\n","# testing data: ONLY use it to measure your model, do NOT use during training.\n","test_x = np.array([sub_x for index, sub_x in enumerate(x) if index in test_lists])\n","test_y = np.array([sub_y for index, sub_y in enumerate(y) if index in test_lists])"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4LdQ5yubLJld"},"source":["In the assignment 2, you have more freedom on your programming design. In this part, you are going to implement your own Logistic Regression function. You need to implement logistic regression with stochastic gradient descent from scratch. The required functions are listed below. You can add more functions as you need. **No library versions of logistic regression are allowed**. \n","_________\n","\n","1. train_val_split\n","\n","**Randomly** split training data into train and val set. 80% of the training data will be the train set and 20% of the training data will be the val set.\n","\n","2. normalization (data preprocessing)\n","\n","You should normalize all data for each attribute firstly. \n","\n","3. sigmoid\n","\n","The core of logistic regression\n","\n","4. predict\n","\n","Predict an output value for a given x with a set of coefficients. \n","\n","5. accurate\n","\n","Calculate accuracy percentage of the predictions.\n","\n","6. coef_gd\n","\n","Estimate logistic regression coefficients using **vanilla gradient descent**. Using **the cross entropy loss**. Carefully choose learning rate and epochs values.\n","\n","7. draw_model\n","\n","a) Plot the both training loss and validation loss for each epochs.\n","\n","b) Plot the both training accuracy and validation accuracy for each epochs. \n","\n","8. predict the testing data\n","\n","Use your pre-trained model to predict the testing data. Print out your **testing accurate**. Is it good? If not, analyze the reason in short and modify your code to improve.  \n"]},{"cell_type":"code","source":["def train_val_split (train_x,train_y, ValidationPercentage=0.2):\n","#1 train_val_split\n","  np.random.seed(seed=2311)\n","#create the validation indexes\n","  index2= np.arange(len(train_x))\n","  np.random.shuffle(index2)\n","  ValidationIndexes= index2[0:round(len(train_x)*ValidationPercentage)]\n","\n","#Create the validation sample\n","  validation_x = np.array([sub_x for index, sub_x in enumerate(train_x) if index in ValidationIndexes])\n","  validation_y = np.array([sub_y for index, sub_y in enumerate(train_y) if index in ValidationIndexes])\n","\n","#Create the training sample\n","  training_x = np.array([sub_x for index, sub_x in enumerate(train_x) if index not in ValidationIndexes])\n","  training_y = np.array([sub_y for index, sub_y in enumerate(train_y) if index not in ValidationIndexes])\n","\n","  return(training_x,validation_x,training_y,validation_y)\n","\n","\n","\n","def normalization(array):\n","\n","  Highest=np.array([])\n","  Lowest=np.array([])\n","\n","  for i in array.T:\n","    Highest=np.append(Highest,max(i))\n","    Lowest=np.append(Lowest,min(i))\n","  arrayN=(array-Lowest)/(Highest-Lowest)\n","\n","  return arrayN\n","\n","def sigmoid(x):\n","  z = 1/(1 + np.exp(-x))\n","  return z\n","\n","def predict(x,coefficients):\n","  x2=np.append(np.array([1]),x)\n","  s=sum(x2*coefficients)\n","  return round(sigmoid(s))\n","\n","def probability(x,coefficients):\n","  x2=np.append(np.array([1]),x)\n","  s=sum(x2*coefficients)\n","  return sigmoid(s)\n","\n","def accurate(y,predictions):\n","  success= y==predictions\n","  return(success.sum()/len(success))\n","\n","def calculateLoss(y,probabilities):\n","  loss=-sum(y*np.log(probabilities)+(1-y)*np.log(1-probabilities))\n","  return loss\n","\n","\n","\n","def coef_gd( x, y,x_val,y_val, l=0.02, epochs=100):\n","  x=normalization(x)\n","  x_val=normalization(x_val)\n","  coefficients=np.random.randn(len(x.T)+1)\n","  loss=np.array([])\n","  ValLoss=np.array([])\n","\n","  ACC=np.array([])\n","  ValACC=np.array([])\n","\n","  for epoch in range(epochs):\n","    predictions=np.array([])\n","    probabilities=np.array([])\n","    Valpredictions=np.array([])\n","    Valprobabilities=np.array([])\n","    \n","#Make predictions and get probabilities\n","    for row in x:\n","      predictions=np.append(predictions,predict(x=row, coefficients=coefficients))\n","      probabilities=np.append(probabilities,probability(x=row,coefficients=coefficients))\n","#Calculate the loss and accuracy\n","    loss=np.append(loss,calculateLoss(y,probabilities))\n","    ACC=np.append(ACC,accurate(y,predictions))\n","#Calculate the validation loss\n","    for row in x_val:\n","      Valpredictions=np.append(Valpredictions,predict(x=row, coefficients=coefficients))\n","      Valprobabilities=np.append(Valprobabilities,probability(x=row,coefficients=coefficients))\n","#Calculate the validation loss and accuracy\n","    ValLoss=np.append(ValLoss,calculateLoss(y_val,Valprobabilities))\n","    ValACC=np.append(ValACC,accurate(y_val,Valpredictions))\n","#Update the weights\n","    for col in range(len(coefficients)):\n","      s=0\n","      for row in range(len(x)):\n","        s=s-(y[row]-probabilities[row])*np.append(np.array([1]),x[row,:])[col]\n","      coefficients[col]=coefficients[col]-l*s\n","  return coefficients, loss, ValLoss, ACC, ValACC\n","\n","def draw_model(loss,ValLoss,ACC,ValACC):\n","#Plot the training and validation loss\n","  fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n","  ax.plot(range(len(loss)), loss, label='Training Loss')  \n","  ax.plot(range(len(ValLoss)), ValLoss, label='Validation Loss') \n","  ax.set_xlabel('Epoch') \n","  ax.set_ylabel('Loss') \n","  ax.set_title(\"Training and validation loss in epochs\")  \n","  plt.legend()\n","\n","#Plot the training and validation Accuracy\n","  fig2, ax2 = plt.subplots(figsize=(5, 2.7), layout='constrained')\n","  ax2.plot(range(len(ACC)), ACC, label='Training Accuracy')  \n","  ax2.plot(range(len(ValACC)), ValACC, label='Validation Accuracy') \n","  ax2.set_xlabel('Epoch') \n","  ax2.set_ylabel('Accuracy') \n","  ax2.set_title(\"Training and validation Accuracy in epochs\")  \n","  plt.legend()\n","\n","\n","##Main: divide between validation and training\n","training_x,validation_x,training_y,validation_y = train_val_split(train_x,train_y, ValidationPercentage=0.2)\n","\n","#perform the descent\n","weights, loss, ValLoss, ACC, ValACC = coef_gd(x=training_x, x_val=validation_x, y_val=validation_y, y=training_y, l=0.02, epochs=100)\n","\n","#draw the results of the losses\n","draw_model(loss=loss,ValLoss=ValLoss,ACC=ACC,ValACC=ValACC)\n","\n","#Predict the testing data\n","pred=np.array([])\n","for row in normalization(test_x):\n","      pred=np.append(pred,predict(x=row, coefficients=weights))\n","print(\"The predicted values are:\",pred.astype(int))\n","print(\"And the testing ones are:\",test_y)\n","print(\"The testing accuracy is :\",sum(pred==test_y)/len(test_y),\"which is very high\")\n"],"metadata":{"id":"6AHamaj3f5xY","colab":{"base_uri":"https://localhost:8080/","height":473},"executionInfo":{"status":"ok","timestamp":1677381814785,"user_tz":360,"elapsed":6256,"user":{"displayName":"Javier Echavarren Suárez","userId":"10032767525210246133"}},"outputId":"0cf74daa-033d-4b7b-ac43-2661324a2739"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["The predicted values are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","And the testing ones are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","The testing accuracy is : 1.0 which is very high\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 360x194.4 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 360x194.4 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"7eNsYoFL7pOG"},"source":["### - Naive Bayes Classifier"]},{"cell_type":"markdown","metadata":{"id":"HTuXPz9V8jIA"},"source":["In this part, you are going to implement your own naive bayes classifier. \n","You need to implement naive bayes classifier from scratch **using the training data of wine datasets train_x and train_y**. The required functions are listed below. You can add more functions as you need. **No library versions of naive bayes classifier are allowed**. \n","_________\n","\n","1. train_val_split\n","\n","**Randomly** split training data into train and val set. 80% of the training data will be the train set and 20% of the training data will be the val set.\n","\n","2. normalization (data preprocessing)\n","\n","You should normalize all data for each attribute firstly. \n","\n","3. cross_validation_split\n","\n","**Randomly** split data into 5 folds.\n","\n","\n","4. predict\n","\n","Predict the class label for a given x. \n","\n","5. accurate\n","\n","Calculate accuracy percentage of the predictions. Remember to average the results of k folds\n","\n","6. gaussian_probability\n","\n","Calculate the Gaussian probability distribution function for the given x. \n","\n","![Image_20210920015911.png](data:image/png;base64,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)\n","\n","\n","5. class_probability\n","\n","Calculate the probabilities of predicting each class for a given x using naive bayes algorithm. Be aware that we have multiple input variables. And you may want to use gaussian_probability function here.\n","\n","*Print out your accuracy result. Is it good? If not, analyze the reason in short. *\n"]},{"cell_type":"code","metadata":{"id":"f-jO9XrADS92","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677381842783,"user_tz":360,"elapsed":138,"user":{"displayName":"Javier Echavarren Suárez","userId":"10032767525210246133"}},"outputId":"3ae5b83c-377e-45ec-9f39-9788d720b202"},"source":["def train_val_split (train_x,train_y, ValidationPercentage=0.2):\n","#1 train_val_split\n","  np.random.seed(seed=2311)\n","#create the validation indexes\n","  index2= np.arange(len(train_x))\n","  np.random.shuffle(index2)\n","  ValidationIndexes= index2[0:round(len(train_x)*ValidationPercentage)]\n","\n","#Create the validation sample\n","  validation_x = np.array([sub_x for index, sub_x in enumerate(train_x) if index in ValidationIndexes])\n","  validation_y = np.array([sub_y for index, sub_y in enumerate(train_y) if index in ValidationIndexes])\n","\n","#Create the training sample\n","  training_x = np.array([sub_x for index, sub_x in enumerate(train_x) if index not in ValidationIndexes])\n","  training_y = np.array([sub_y for index, sub_y in enumerate(train_y) if index not in ValidationIndexes])\n","\n","  return(training_x,validation_x,training_y,validation_y)\n","\n","def normalization(array):\n","\n","  Highest=np.array([])\n","  Lowest=np.array([])\n","\n","  for i in array.T:\n","    Highest=np.append(Highest,max(i))\n","    Lowest=np.append(Lowest,min(i))\n","  arrayN=(array-Lowest)/(Highest-Lowest)\n","\n","  return arrayN\n","\n","def cross_validation_split (train_x,train_y, K=5):\n","\n","  np.random.seed(seed=2311)\n","  #create the validation indexes\n","  index2= np.arange(len(train_x))\n","  np.random.shuffle(index2)\n","  kIndexes=[]\n","\n","  for i in range(K):\n","    kIndexes.append(index2[round(len(train_x)*(i/K)):round(len(train_x)*((i+1)/K))])\n","\n","  #Create the k samples\n","  k_x = []\n","  k_y = []\n","\n","  for i in range(K):\n","    k_x.append(np.array([sub_x for index, sub_x in enumerate(train_x) if index in kIndexes[i]]))\n","    k_y.append(np.array([sub_y for index, sub_y in enumerate(train_y) if index in kIndexes[i]]))\n","\n","  return k_x,k_y\n","\n","def calculate_m_sd(x):\n","  m_sd = np.zeros((2,len(x.T)))\n","  for col in range(len(x.T)):\n","    m_sd[0,col]=np.mean(x[col])\n","    m_sd[1,col]=np.std(a=x[col], ddof=1)\n","  return m_sd\n","\n","def gaussian_probability(x,m,sd):\n","  exponent = np.exp(-((x-m)**2 / (2 * sd**2 )))\n","  return (1 / (np.sqrt(2 * np.pi) * sd)) * exponent\n","\n","\n","\n","\n","def predict(m_sd0,m_sd1,vector):\n","  p0=1\n","  p1=1\n","\n","  for i in range(len(vector)):\n","    p0=p0*gaussian_probability(vector[i],m_sd0[0,i],m_sd0[1,i])\n","    p1=p1*gaussian_probability(vector[i],m_sd1[0,i],m_sd1[1,i])\n","  if p0>p1:\n","    result=0\n","  else:\n","    result=1\n","  return result\n","\n","def separate01(kx,ky):\n","  index0 = ky[0]==0\n","  index1 = ky[0]==1\n","  k0 = kx[0][index0]\n","  k1 = kx[0][index1]\n","  for i in range(1,len(ky)):\n","    index0 = ky[i]==0\n","    k0= np.append(k0,kx[i][index0], axis=0)\n","    index1 = ky[i]>0\n","    k1= np.append(k1,kx[i][index1], axis=0)\n","  return(k0,k1)\n","\n","def accurate(kx, ky, x_test, y_test):\n","  k0, k1 = separate01(kx,ky)\n","  m_sd0 = calculate_m_sd(k0)\n","  m_sd1 = calculate_m_sd(k1)\n","  prediction = []\n","  for vector in x_test:\n","    prediction.append(predict(m_sd0=m_sd0, m_sd1 = m_sd1, vector = vector))\n","  ACC = np.mean(y_test==prediction)\n","  return ACC\n","\n","def accurateKfold(kx,ky):\n","  accuracyv=np.zeros(len(kx))\n","  for i in range(len(kx)):\n","    kx2=[]\n","    ky2=[]\n","    for j in range(len(kx)):\n","      if(j!=i):\n","        kx2.append(kx[j])\n","        ky2.append(ky[j])\n","    accuracyv[i] =accurate(kx2,ky2,kx[i],ky[i])\n","    meanaccuracy=np.mean(accuracyv)\n","\n","  return meanaccuracy\n","\n","def class_probability(m_sd0,m_sd1,vector,P1general):\n","  p0C=1\n","  p1C=1\n","\n","  for i in range(len(vector)):\n","    p0C=p0C*gaussian_probability(vector[i],m_sd0[0,i],m_sd0[1,i])\n","    p1C=p1C*gaussian_probability(vector[i],m_sd1[0,i],m_sd1[1,i])\n","  cprobability0=(p0C*(1-P1general))/((p0C*(1-P1general))+(p1C*P1general))\n","  cprobability1=(p1C*(P1general))/((p0C*(1-P1general))+(p1C*P1general))\n","  return cprobability0,cprobability1\n","\n","\n","##Main: divide between validation and training\n","training_x,validation_x,training_y,validation_y = train_val_split(train_x,train_y, ValidationPercentage=0.2)\n","\n","#Normalize\n","training_x=normalization(training_x)\n","\n","#get the k folds\n","kx,ky = cross_validation_split(training_x,training_y,K=5)\n","\n","#build the model and test the accuracy on the k folds\n","meanACC= accurateKfold(kx,ky)\n","\n","#get m_sd of the full training data\n","k0,k1 = separate01(kx,ky)\n","m_sd0=calculate_m_sd(k0)\n","m_sd1=calculate_m_sd(k1)\n","p1General = len(k1)/(len(k0)+len(k1))\n","\n","#Get the class probabilities for the test data\n","test_xN = normalization(test_x)\n","probability=[]\n","for i in range(len(test_x)):\n","  probability.append(class_probability(m_sd0=m_sd0, m_sd1= m_sd1, vector = test_xN[i], P1general = p1General))\n","\n","#Get predictions for the testing data and print the results\n","probability = np.array(probability)\n","predictions = (probability.T[0]<probability.T[1])*1\n","print(\"The predicted values are:\",predictions)\n","print(\"The test values are\",test_y)\n","accuracyTest = np.mean(predictions==test_y)\n","print(\"The model has a\", accuracyTest*100,\"% accuracy, which is good enough, but worse than that of the logistic regression.This model does not change iteratively to fit better, and that is why the other logistic regression did better.\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The predicted values are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0]\n","The test values are [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","The model has a 76.66666666666667 % accuracy, which is good enough, but worse than that of the logistic regression.This model does not change iteratively to fit better, and that is why the other logistic regression did better.\n"]}]}]}